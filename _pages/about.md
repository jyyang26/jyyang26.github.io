---
permalink: /
title: "Junyao Yang(æ¨ç«£å°§) @AAAI 2026"
layout: single
author_profile: true
redirect_from:Â 
Â  - /about/
Â  - /about.html
---

<style>
    /* å…¨å±€å˜é‡ä¸åŸºç¡€è®¾ç½® - è¥é€ é«˜çº§æ„Ÿçš„å…³é”® */
    :root {
        --accent-color: #4a729a; /* æ›¿æ¢åŸæœ¬åˆºçœ¼çš„äº®è‰²ï¼Œä½¿ç”¨æ²‰ç¨³çš„è“ç°è‰² */
        --text-color: #333333;
        --bg-secondary: #f8f9fa; /* ææ·¡çš„ç°èƒŒæ™¯ */
        --border-color: #eaeaea;
        --card-shadow: 0 8px 24px rgba(0, 0, 0, 0.04); /* å¼¥æ•£é˜´å½± */
        --hover-shadow: 0 12px 32px rgba(0, 0, 0, 0.08);
    }

    body {
        font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif;
        color: var(--text-color);
        line-height: 1.6;
    }

    a {
        color: var(--accent-color);
        text-decoration: none;
        transition: color 0.2s;
    }
    
    a:hover {
        color: #2c4a68;
        text-decoration: underline;
    }

    /* æ ‡é¢˜æ ·å¼å¾®è°ƒ */
    h1, h2, h3 {
        font-weight: 600;
        letter-spacing: -0.02em;
        margin-top: 1.5em;
        margin-bottom: 0.8em;
    }

    /* --- News æ¨¡å—ç¾åŒ– (æ—¶é—´è½´é£æ ¼) --- */
    .news-container {
        max-height: 350px;
        overflow-y: auto;
        padding-right: 10px;
        /* è‡ªå®šä¹‰æ»šåŠ¨æ¡æ ·å¼ */
        scrollbar-width: thin; 
        scrollbar-color: #ccc #f0f0f0;
    }
    
    .news-container::-webkit-scrollbar {
        width: 4px;
    }
    .news-container::-webkit-scrollbar-thumb {
        background-color: #ccc;
        border-radius: 4px;
    }
    .news-container::-webkit-scrollbar-track {
        background-color: #f0f0f0;
    }

    .news-list {
        list-style: none;
        padding-left: 15px;
        border-left: 2px solid #eee; /* å·¦ä¾§æ—¶é—´è½´çº¿ */
        margin: 0;
    }

    .news-list li {
        position: relative;
        margin-bottom: 18px;
        padding-left: 15px;
        font-size: 0.95em;
    }

    /* æ—¶é—´è½´ä¸Šçš„å°åœ†ç‚¹ */
    .news-list li::before {
        content: '';
        position: absolute;
        left: -20px; /* è°ƒæ•´åœ†ç‚¹ä½ç½®ä»¥å¯¹é½çº¿ */
        top: 8px;
        width: 8px;
        height: 8px;
        border-radius: 50%;
        background: var(--accent-color);
        border: 2px solid #fff;
    }

    /* --- è®ºæ–‡å¡ç‰‡ (Paper Card) --- */
    .paper-card {
        display: flex;
        flex-direction: column; /* ç§»åŠ¨ç«¯ä¼˜å…ˆ */
        margin-bottom: 24px;
        padding: 20px;
        border-radius: 12px;
        background-color: #fff;
        border: 1px solid var(--border-color);
        transition: all 0.3s ease;
    }

    @media (min-width: 768px) {
        .paper-card {
            flex-direction: row;
        }
    }

    .paper-card:hover {
        box-shadow: var(--card-shadow);
        transform: translateY(-2px);
        border-color: transparent;
    }

    .paper-img-box {
        width: 100%;
        margin-bottom: 15px;
        flex-shrink: 0;
    }
    
    @media (min-width: 768px) {
        .paper-img-box {
            width: 180px;
            margin-bottom: 0;
            margin-right: 24px;
        }
    }

    .paper-img {
        width: 100%;
        height: auto;
        border-radius: 6px;
        border: 1px solid #f0f0f0;
        display: block;
    }

    .paper-content {
        flex: 1;
    }

    .paper-title {
        font-size: 1.05em;
        font-weight: 700;
        color: var(--accent-color) !important;
        display: block;
        margin-bottom: 6px;
    }

    .tldr-box {
        background-color: var(--bg-secondary);
        border-radius: 6px;
        padding: 10px 14px;
        color: #666;
        font-size: 0.85em;
        margin-top: 10px;
        line-height: 1.5;
    }
    
    .link-row {
        margin-top: 10px;
        font-size: 0.85em;
    }
    
    .link-sep {
        margin: 0 8px;
        color: #ddd;
    }

    /* --- æ•™è‚²ä¸ç»å†å¡ç‰‡ (Flexå¸ƒå±€æ›¿ä»£Float) --- */
    .info-card {
        display: flex;
        justify-content: space-between;
        align-items: flex-start;
        padding: 15px 0;
        border-bottom: 1px dashed #eee;
    }
    
    .info-card:last-child {
        border-bottom: none;
    }

    .info-text {
        flex: 1;
        padding-right: 20px;
    }
    
    .info-logo {
        flex-shrink: 0;
        width: 70px; /* ç¨å¾®è°ƒå°Logoæ˜¾å¾—æ›´ç²¾è‡´ */
        height: 70px;
        display: flex;
        align-items: center;
        justify-content: center;
        background: #fff;
        border-radius: 8px;
        padding: 5px;
        box-shadow: 0 2px 8px rgba(0,0,0,0.03);
        border: 1px solid #fafafa;
    }

    .info-logo img {
        width: 100%;
        height: 100%;
        object-fit: contain;
    }
</style>

ğŸ‘‹ Hi there, my name is Junyao Yang. I am a graduate student at the School of Computing, National University of Singapore (NUS), where I am pursuing a specialization in Artificial Intelligence. My research interests lie in **Natural Language Processing**, **Explainable Artificial Intelligence** and **Trustworthy Machine Learning**. Here is my **[CV](https://drive.google.com/file/d/17UEE4NB9HbyNba8TwQ5oO3y3Tu7hwhZm/view?usp=sharing)**.

My research story revolves around **the Underlying Principles and Understanding of Artificial Intelligence**, particularly focusing on how to enhance the **"Robustness"** and **"Safety"** of LLM-generated information and understand the **Interpretability** of model mechanisms, which connects to related areas such as **Trustworthy LLM** [**[ACL 2025 Main](https://arxiv.org/abs/2406.01394)**, **[EMNLP 2025 Main](https://arxiv.org/abs/2502.18517)**], **Reasoning Model Merging** [**[AAAI 2026](https://arxiv.org/abs/2508.03140)**, **[ReasonAny](https://arxiv.org/abs/2601.05560)**] and **Malicious Attacks** [**[ACL 2025 Main](https://arxiv.org/abs/2406.01394)**], of LLMs and so on:

- **Trustworthy Artificial Intelligence**
- **Large Language Models Reasoning**

Â # ğŸ”¥ News {#news}

<div class="news-container">
Â  <ul class="news-list">
Â  Â  <li>
Â  Â  [2026.01]Â  ğŸ„â€â™‚ï¸ğŸ„â€â™‚ï¸ I will attend <strong>AAAI 2026 at Singapore during Jan 20-27</strong>, 2026. Letâ€™s connect!
Â  Â  Â  </li>
Â  Â  <li>
Â  Â  Â  [2026.01] ğŸš€ğŸš€ Please check our latest paper: <strong><a href="https://arxiv.org/abs/2601.05560">ReasonAny</a></strong>! ReasonAny employs contrastive gradient identification to resolve destructive performance collapse, effectively merging reasoning capabilities into domain-specific models.
Â  Â  </li>
Â  Â  <li>
Â  Â  Â  [2025.11] ğŸ‰ğŸ‰ <strong>First-Author paper</strong> <a href="https://arxiv.org/abs/2508.03140"><strong>RCP-Merging</strong></a> has been accepted to <strong>AAAI 2026 Main Track</strong>! See you in Singapore!
Â  Â  </li>
Â  Â  <li>
Â  Â  Â  [2025.08] ğŸ‰ğŸ‰ <a href="https://arxiv.org/abs/2502.18517"><strong>RewardDS</strong></a> has been accepted to <strong>EMNLP 2025 Main</strong>!
Â  Â  </li>
Â  Â  <li>
Â  Â  Â  [2025.08] I joined <a href="https://ai45.shlab.org.cn/">Shanghai AI Lab</a> as a Research Intern, advised by <a href="https://shenqildr.github.io/">Dongrui Liu</a>.
Â  Â  </li>
Â  Â  <li>
Â  Â  Â  [2025.08] ğŸš€ğŸš€ Check out my latest work: <strong><a href="https://arxiv.org/abs/2508.03140"><strong>RCP-Merging</strong></a></strong>! This novel framework integrates long CoT capability into domain-specific LLMs without sacrificing their performance in the original domain!
Â  Â  </li>
Â  Â  <li>
Â  Â  Â  [2025.05] ğŸ‰ğŸ‰ Successfully passed my undergraduate thesis defense!
Â  Â  </li>
Â  Â  <li>
Â  Â  Â  [2025.05] ğŸ‰ğŸ‰ <strong>Co-First-Author paper</strong> <a href="https://arxiv.org/abs/2406.01394"><strong>PrivacyRestore</strong></a> has been accepted to <strong>ACL 2025 Main</strong>! Deeply grateful to my mentor Ziqian and collaborator Jianwei! See you in Vienna!
Â  Â  </li>
Â  Â  <li>
Â  Â  Â  [2025.02] ğŸš€ğŸš€ Please check our newest papers: <strong><a href="https://arxiv.org/abs/2502.18517">RewardDS</a></strong> and <strong><a href="https://arxiv.org/abs/2406.01394">PrivacyRestore</a></strong>! Thanks to the help of other collaborators.
Â  Â  </li>
Â  Â  <li>
Â  Â  Â  [2024.07] I joined <a href="https://github.com/ZeroNLP">ZeroNLP</a> as a Research Assistant, advised by Prof. <a href="https://ziqianzeng.github.io/">Ziqian Zeng</a>.
Â  Â  </li>
Â  Â  <li>
Â  Â  Â  [2024.07] I spent a wonderful time at Tencent as a machine learning intern!
Â  Â  </li>
Â  Â  <li>
Â  Â  Â  [2024.07] <strong>Contextless CS</strong> is available now, which reaches <strong>20,000 DAU</strong>! Check my work <strong><a href="https://kf.qq.com/">here</a></strong>!
Â  Â  </li>
Â  Â  <li>
Â  Â  Â  [2024.04] I joined Tencent as a machine learning intern.
Â  Â  </li>
Â  Â  <li>
Â  Â  Â  [2024.03] I spent a wonderful time at ShenZhen Stock Exchange as a machine learning intern!
Â  Â  </li>
Â  </ul>
</div>

<br>

# ğŸ§ Publications {#research}

<div class="paper-card">
Â  <div class="paper-img-box">
Â  Â  <a href="https://arxiv.org/abs/2601.05560" style="display: block;">
Â  Â  Â  <img src="images/ReasonAny_main_fig.png" alt="ReasonAny" class="paper-img">
Â  Â  </a>
Â  </div>
Â  <div class="paper-content">
Â  Â  <span style="font-size: 0.9em; color: #888;"><strong><em>[arXiv Preprint]</em></strong></span><br>
Â  Â  <a href="https://arxiv.org/abs/2601.05560" class="paper-title">ReasonAny: Incorporating Reasoning Capability to Any Model via Simple and Effective Model Merging</a>
Â  Â  <strong>Junyao Yang</strong>, <em>Chen Qian, Dongrui Liu<sup>*#</sup>, Wen Shen, Yong Liu<sup>*#</sup>, Jing Shao<sup>*#</sup></em><br>

Â  Â  <div class="tldr-box">
Â  Â  Â  <strong>TL;DR:</strong> A training-free framework that resolves "destructive performance collapse" by identifying that reasoning relies on low-gradient parameters. It employs Contrastive Gradient Identification to successfully merge robust chain-of-thought capabilities into domain-specific models (Safety, Biomedicine, Finance) without compromising their specialized utility.
Â  Â  </div>
Â  Â Â 
Â  Â  <div class="link-row">
Â  Â  Â  <a href="https://arxiv.org/abs/2601.05560">arXiv</a>
Â  Â  Â  <span class="link-sep">/</span>
Â  Â  Â  <a href="https://github.com/jyyang26/ReasonAny">Code</a>
Â  Â  </div>
Â  </div>
</div>

<div class="paper-card">
Â  <div class="paper-img-box">
Â  Â  <a href="https://arxiv.org/abs/2508.03140" style="display: block;">
Â  Â  Â  <img src="images/rcp.png" alt="rcp" class="paper-img">
Â  Â  </a>
Â  </div>
Â  <div class="paper-content">
Â  Â  <span style="font-size: 0.9em; color: #888;"><strong>[AAAI 2026 Main Track]</strong></span><br>
Â  Â  <a href="https://arxiv.org/abs/2508.03140" class="paper-title">RCP-Merging: Merging Long Chain-of-Thought Models with Domain-Specific Models by Considering Reasoning Capability as Prior</a>
Â  Â  <strong>Junyao Yang</strong>, <em>Jianwei Wang, Huiping Zhuang, Cen Chen, Ziqian Zeng<sup>*#</sup></em><br>

    <div class="tldr-box">
Â  Â  Â  <strong>TL;DR:</strong> A model merging framework that integrates domain-specific models with reasoning models by treating reasoning capabilities as a prior, enhancing domain performance while preserving chain-of-thought reasoning abilities.
Â  Â  </div>
Â  Â Â 
Â  Â  <div class="link-row">
Â  Â  Â  <a href="https://arxiv.org/abs/2508.03140">arXiv</a>
Â  Â  Â  <span class="link-sep">/</span>
Â  Â  Â  <a href="https://github.com/ZeroNLP/RCP-Merging">Code</a>
Â  Â  </div>
Â  </div>
</div>

<div class="paper-card">
Â  <div class="paper-img-box">
Â  Â  <a href="https://arxiv.org/abs/2406.01394" style="display: block;">
Â  Â  Â  <img src="images/restore.png" alt="restore" class="paper-img">
Â  Â  </a>
Â  </div>
Â  <div class="paper-content">
Â  Â  <span style="font-size: 0.9em; color: #888;"><strong>[ACL 2025 Main]</strong></span><br>
Â  Â  <a href="https://arxiv.org/abs/2406.01394" class="paper-title">PrivacyRestore: Privacy-Preserving Inference in Large Language Models via Privacy Removal and Restoration</a>
Â  Â  <em>Ziqian Zeng<sup>*#</sup>, Jianwei Wang<sup>*</sup>, <strong>Junyao Yang<sup>*</sup></strong>, Zhengdong Lu, Haoran Li, Huiping Zhuang, Cen Chen</em><br>

Â  Â  <div class="tldr-box">
Â  Â  Â  <strong>TL;DR:</strong> A privacy-preserving inference framework that removes privacy information from user inputs and restores them on the server via activation steering using a protected meta-vector, ensuring data privacy without retraining.
Â  Â  </div>
Â  Â Â 
Â  Â  <div class="link-row">
Â  Â  Â  <a href="https://arxiv.org/abs/2406.01394">arXiv</a>
Â  Â  Â  <span class="link-sep">/</span>
Â  Â  Â  <a href="https://github.com/ZeroNLP/PrivacyRestore">Code</a>
Â  Â  </div>
Â  </div>
</div>

<div class="paper-card">
Â  <div class="paper-img-box">
Â  Â  <a href="https://arxiv.org/abs/2502.18517" style="display: block;">
Â  Â  Â  <img src="images/rewardds.png" alt="rewardds" class="paper-img">
Â  Â  </a>
Â  </div>
Â  <div class="paper-content">
Â  Â  <span style="font-size: 0.9em; color: #888;"><strong>[EMNLP 2025 Main]</strong></span><br>
Â  Â  <a href="https://arxiv.org/abs/2502.18517" class="paper-title">RewardDS: Privacy-Preserving Fine-Tuning for Large Language Models via Reward Driven Data Synthesis</a>
Â  Â  <em>Jianwei Wang, Chengming Shi, <strong>Junyao Yang</strong>, Haoran Li, Huiping Zhuang, Cen Chen, Ziqian Zeng<sup>#</sup></em><br>
    
Â  Â  <div class="tldr-box">
Â  Â  Â  <strong>TL;DR:</strong> A privacy-preserving fine-tuning framework that improves synthetic data quality by using a client-side reward model to filter and refine generated data, mitigating noise while protecting private information.
Â  Â  </div>
Â  Â Â 
Â  Â  <div class="link-row">
Â  Â  Â  <a href="https://arxiv.org/abs/2502.18517">arXiv</a>
Â  Â  Â  <span class="link-sep">/</span>
Â  Â  Â  <a href="https://github.com/wjw136/RewardDS">Code</a>
Â  Â  </div>
Â  </div>
</div>

<span style="color: #999; font-size: 0.85em;"><sub>(<sup>\*</sup> co-author, <sup>#</sup> correspondence author)</sub></span>


âœï¸ Education {#education}
======

<div class="info-card">
    <div class="info-text">
        - **National University of Singapore**, Singapore <br>
        Â  M.S. in Artificial Intelligence <br>
        Â  2025 ~ 2027 (expected) <br>
    </div>
    <div class="info-logo">
        <img src="images/NUS.jpg" alt="NUS">
    </div>
</div>

<div class="info-card">
    <div class="info-text">
        - **South China University of Technology**, Guangzhou, ChinaÂ Â <br>
        Â  B.E. in Computer Science Union Class (top 30 students in undergraduates)Â Â <br>
        Â  2021 ~ 2025
    </div>
    <div class="info-logo">
        <img src="images/South_China_University_of_Technology_Logo_(Since_2022).svg.png" alt="SCUT">
    </div>
</div>

<div class="info-card">
    <div class="info-text">
        - **Shenzhen Experimental School**, Shenzhen, ChinaÂ Â <br>
        Â  High School DiplomaÂ Â <br>
        Â  2018 ~ 2021
    </div>
    <div class="info-logo">
        <img src="images/SZSY_Logo.png" alt="SZSY">
    </div>
</div>


ğŸ’» Experience {#experience}
======

<div class="info-card">
    <div class="info-text">
        - 2025.06 ~ Present, Research Intern, Shanghai AI Lab <br>
        Â  Supervisor: [Dongrui Liu](https://shenqildr.github.io/), Collaborator: [Chen Qian](https://scholar.google.com/citations?user=knR4ZusAAAAJ&hl=en), Shanghai, China. <br>
        Â  Topics: Trustworthy Machine Learning & LLM Reasoning <br>
    </div>
    <div class="info-logo">
        <img src="images/ailab.png" alt="ailab">
    </div>
</div>

<div class="info-card">
    <div class="info-text">
        - 2024.07 ~ Present, Research Intern, South China University of Technology <br>
        Â  Supervisor: Prof. [Ziqian Zeng](https://ziqianzeng.github.io/), Collaborator: [Jianwei Wang](https://scholar.google.com/citations?user=eRFVxQ8AAAAJ&hl=zh-CN), [Haoran Li](https://hlibt.student.ust.hk/), Guangzhou, China. <br>
        Â  Topics: LLM Privacy & Reasoning <br>
    </div>
    <div class="info-logo">
        <img src="images/South_China_University_of_Technology_Logo_(Since_2022).svg.png" alt="SCUT">
    </div>
</div>

<div class="info-card">
    <div class="info-text">
        - 2024.04 ~ 2024.07, Machine Learning Intern, **[Tencent](https://kf.qq.com/)**, Shenzhen, China. <br>
        Â  Topics: LLM Deployment & Fine-Tuning <br>
    </div>
    <div class="info-logo">
        <img src="images/Tencent.png" alt="Tencent">
    </div>
</div>

<div class="info-card">
    <div class="info-text">
        - 2024.01 ~ 2024.04, Machine Learning Intern, **[SZSE](https://www.szse.cn/English/index.html)**, Shenzhen, China. <br>
        Â  Topics: LLM Acceleration & Memory OptimizingÂ  <br>
    </div>
    <div class="info-logo">
        <img src="images/SZSE.png" alt="szse">
    </div>
</div>

<div class="info-card">
    <div class="info-text">
        - 2023.06 ~ 2024.08, Research Intern, South China University of Technology <br>
        Â  Supervisor: Prof. [Guanglong Du](https://www2.scut.edu.cn/duguanglong/), Guangzhou, China. <br>
        Â  Topics: Reinforcement Learning & UAV Navigation <br>
    </div>
    <div class="info-logo">
        <img src="images/South_China_University_of_Technology_Logo_(Since_2022).svg.png" alt="SCUT">
    </div>
</div>


ğŸ–ï¸ Honor and Awards {#honor}
======
- [2025.06] Excellent Graduation Thesis
-	[2024.10] Second-Class Scholarship of South China University of Technology
- [2024.11 & 2023.11 & 2022.11] Outstanding Student LeaderÂ 
- [2024.11 & 2023.11 & 2022.11] Merit StudentÂ 
- [2023.05] Outstanding Student Union Member
- [2022.10] Third-Class Scholarship of South China University of Technology
- [2022.09] Second-Class Award in CUMCM at Guangdong ProvinceÂ 

ğŸ“˜ Patents
======
**An Intelligent Obstacle Avoidance and Destination Landing Unmanned Aerial Vehicles Based on Multi-Layer Neural Networks**<br>
*Guanglong Du, Xiaojian Qiu, **Junyao Yang**, Jiancheng Li, Xueqian Wang, Xiaojun Zhu* (Student First Author)<br>
2023.08Â  Publication Number: CN117170403AÂ Â 


<br>
<div style="width: 180px; margin: 40px auto; text-align: center; opacity: 0.8;">
Â  <script type="text/javascript" id="clustrmaps" src="//clustrmaps.com/map_v2.js?d=fHE-8Jdi8dG4h8kH9bKTC8OPRf52B9shV3EzW7J6MMc&cl=ffffff&w=a"></script>
</div>
