---
permalink: /
title: "Junyao Yang(æ¨ç«£å°§)"
layout: single
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

ğŸ‘‹ Hi there, my name is Junyao Yang. I am a graduate student at the School of Computing, National University of Singapore (NUS), where I am pursuing a specialization in Artificial Intelligence. My research interests lie in **Natural Language Processing** and **Trustworthy Machine Learning**. Here is my **[CV](https://drive.google.com/file/d/17UEE4NB9HbyNba8TwQ5oO3y3Tu7hwhZm/view?usp=sharing)**.

My research story revolves around **the Underlying Principles and Understanding of LLMs**, particularly focusing on how to enhance the **"Robustness"** and **"Safety"** of LLM-generated information, which connects to related areas such as **Trustworthy LLM** [**[ACL 2025 Main](https://arxiv.org/abs/2406.01394)**, **[EMNLP 2025 Main](https://arxiv.org/abs/2502.18517)**], **Reasoning Model Merging** [**[AAAI 2026](https://arxiv.org/abs/2508.03140)**] and **Malicious Attacks** [**[ACL 2025 Main](https://arxiv.org/abs/2406.01394)**], of LLMs and so on:

- **Trustworthy Artificial Intelligence**
- **Large Language Models Reasoning**

<!-- > Looking for Ph.D. Opportunity in 26Fall/27Spring Intake. -->


<!-- - [2025.02] **RewardDS** is available now! Check our work **[here](https://arxiv.org/abs/2502.18517)**! -->
<!-- - [2024.10] **PrivactRestore** is available now! Check our work **[here](https://arxiv.org/abs/2406.01394)**! -->
 <!--  a novel merging framework that integrates domain-specific LLMs with long Chain-of-Thought (CoT) capability while maintaining performance in their original domain! -->
 
# ğŸ”¥ News {#news}
<div style="max-height: 350px; overflow-y: auto;">
  <ul>
    <li>
      [2026.02] ğŸš€ğŸš€ Please check our newest papers: <strong><a href="https://arxiv.org/abs/2601.05560" style="text-decoration: underline; color: #52ADC8;">ReasonAny</a></strong>! ReasonAny employs contrastive gradient identification to resolve destructive performance collapse, effectively merging reasoning capabilities into domain-specific models.
    </li>
    <li>
      [2025.11] ğŸ‰ğŸ‰ <strong>First-Author paper</strong> <a href="https://arxiv.org/abs/2508.03140" style="text-decoration: underline; color: #52ADC8;"><strong>RCP-Merging</strong></a> has been accepted to <strong>AAAI 2026 Main Track</strong>! See you in Singapore!
    </li>
    <li>
      [2025.08] ğŸ‰ğŸ‰ <a href="https://arxiv.org/abs/2502.18517" style="text-decoration: underline; color: #52ADC8;"><strong>RewardDS</strong></a> has been accepted to <strong>EMNLP 2025 Main</strong>!
    </li>
    <li>
      [2025.08] I joined <a href="https://ai45.shlab.org.cn/" style="text-decoration: underline; color: #52ADC8;">Shanghai AI Lab</a> as a Research Intern, advised by Dr. <a href="https://shenqildr.github.io/" style="text-decoration: underline; color: #52ADC8;">Dongrui Liu</a>.
    </li>
    <li>
      [2025.08] ğŸš€ğŸš€ Check out my latest work: <strong><a href="https://arxiv.org/abs/2508.03140" style="text-decoration: underline; color: #52ADC8;"><strong>RCP-Merging</strong></a></strong>! This novel framework integrates long CoT capability into domain-specific LLMs without sacrificing their performance in the original domain!
    </li>
    <li>
      [2025.05] ğŸ‰ğŸ‰ Successfully passed my undergraduate thesis defense!
    </li>
    <li>
      [2025.05] ğŸ‰ğŸ‰ <strong>Co-First-Author paper</strong> <a href="https://arxiv.org/abs/2406.01394" style="text-decoration: underline; color: #52ADC8;"><strong>PrivacyRestore</strong></a> has been accepted to <strong>ACL 2025 Main</strong>! Deeply grateful to my mentor Ziqian and collaborator Jianwei! See you in Vienna!
    </li>
    <li>
      [2025.02] ğŸš€ğŸš€ Please check our newest papers: <strong><a href="https://arxiv.org/abs/2502.18517" style="text-decoration: underline; color: #52ADC8;">RewardDS</a></strong> and <strong><a href="https://arxiv.org/abs/2406.01394" style="text-decoration: underline; color: #52ADC8;">PrivacyRestore</a></strong>! Thanks to the help of other collaborators.
    </li>
    <li>
      [2024.07] I joined <a href="https://github.com/ZeroNLP" style="text-decoration: underline; color: #52ADC8;">ZeroNLP</a> as a Research Assistant, advised by Prof. <a href="https://ziqianzeng.github.io/" style="text-decoration: underline; color: #52ADC8;">Ziqian Zeng</a>.
    </li>
    <li>
      [2024.07] I spent a wonderful time at Tencent as a machine learning intern!
    </li>
    <li>
      [2024.07] <strong>Contextless CS</strong> is available now, which reaches <strong>20,000 DAU</strong>! Check my work <strong><a href="https://kf.qq.com/" style="text-decoration: underline; color: #52ADC8;">here</a></strong>!
    </li>
    <li>
      [2024.04] I joined Tencent as a machine learning intern.
    </li>
    <li>
      [2024.03] I spent a wonderful time at ShenZhen Stock Exchange as a machine learning intern!
    </li>
  </ul>
  <div style="height: 2em;"></div>
</div>


<br>

# ğŸ§ Publications {#research}

<style>
  /* å®šä¹‰æ‚¬æµ®å¡ç‰‡æ ·å¼ */
  .paper-card {
    display: flex;
    margin-bottom: 20px;
    padding: 15px;
    border-radius: 12px;
    transition: all 0.3s ease;
    background-color: #fff;
  }
  
  /* é¼ æ ‡æ‚¬åœæ—¶çš„æ•ˆæœï¼šæ·»åŠ é˜´å½±å¹¶è½»å¾®ä¸Šæµ® */
  .paper-card:hover {
    box-shadow: 0 10px 25px rgba(0, 0, 0, 0.1);
    transform: translateY(-2px);
  }
</style>


<div class="paper-card">
  <div style="width: 100px; margin-right: 20px; flex-shrink: 0; display: flex; flex-direction: column; gap: 10px;">
    <a href="https://arxiv.org/abs/2601.05560" style="display: block;">
      <img src="images/ReasonAny_github_main_fig.png" alt="ReasonAny" style="width: 100px; height: 100px; object-fit: cover; border-radius: 5px; display: block;">
    </a>
  </div>
   
  <div style="flex: 1;">
    <strong>[arXiv Preprint]</strong><br>
    <strong><a href="https://arxiv.org/abs/2601.05560" style="text-decoration: underline; color: #52ADC8;">ReasonAny: Incorporating Reasoning Capability to Any Model via Simple and Effective Model Merging</a></strong><br>
    <strong>Junyao Yang</strong>, Chen Qian, Dongrui Liu, Wen Shen, Yong Liu, Jing Shao<br>
    <div style="background-color: #f9f9f9; border-left: 4px solid #5fbbf3; padding: 10px; color: #808080; font-size: 80%; margin-top: 8px;">
      <strong>TL;DR:</strong> A training-free framework that resolves "destructive performance collapse" by identifying that reasoning relies on low-gradient parameters. It employs Contrastive Gradient Identification to successfully merge robust chain-of-thought capabilities into domain-specific models (Safety, Biomedicine, Finance) without compromising their specialized utility.
    </div>
  </div>
</div>

<div class="paper-card">
  <div style="width: 100px; margin-right: 20px; flex-shrink: 0; display: flex; flex-direction: column; gap: 10px;">
    <a href="https://arxiv.org/abs/2508.03140" style="display: block;">
      <img src="images/rcp.png" alt="rcp" style="width: 100px; height: 100px; object-fit: cover; border-radius: 5px; display: block;">
    </a>
    <img src="images/AAAI2026.jpg" alt="AAAI2026" style="width: 100px; height: 100px; object-fit: cover; border-radius: 5px; display: block;">
  </div>
  
  <div style="flex: 1;">
    <strong>[AAAI 2026 Main Track]</strong><br>
    <strong><a href="https://arxiv.org/abs/2508.03140" style="text-decoration: underline; color: #52ADC8;">RCP-Merging: Merging Long Chain-of-Thought Models with Domain-Specific Models by Considering Reasoning Capability as Prior</a></strong><br>
    <strong>Junyao Yang</strong>, <em>Jianwei Wang, Huiping Zhuang, Cen Chen, Ziqian Zeng<sup>*#</sup></em><br>
    <div style="background-color: #f9f9f9; border-left: 4px solid #5fbbf3; padding: 10px; color: #808080; font-size: 80%; margin-top: 8px;">
      <strong>TL;DR:</strong> A model merging framework that integrates domain-specific models with reasoning models by treating reasoning capabilities as a prior, enhancing domain performance while preserving chain-of-thought reasoning abilities.
    </div>
  </div>
</div>

<div class="paper-card">
  <div style="width: 100px; margin-right: 20px; flex-shrink: 0; display: flex; flex-direction: column; gap: 10px;">
    <a href="https://arxiv.org/abs/2406.01394" style="display: block;">
      <img src="images/restore.png" alt="restore" style="width: 100px; height: 100px; object-fit: cover; border-radius: 5px; display: block;">
    </a>
    <img src="images/ACL2025.jpg" alt="ACL2025" style="width: 100px; height: 100px; object-fit: cover; border-radius: 5px; display: block;">
  </div>

  <div style="flex: 1;">
    <strong>[ACL 2025 Main]</strong><br>
    <strong><a href="https://arxiv.org/abs/2406.01394" style="text-decoration: underline; color: #52ADC8;">PrivacyRestore: Privacy-Preserving Inference in Large Language Models via Privacy Removal and Restoration</a></strong><br>
    <em>Ziqian Zeng<sup>*#</sup>, Jianwei Wang<sup>*</sup>, <strong>Junyao Yang<sup>*</sup></strong>, Zhengdong Lu, Haoran Li, Huiping Zhuang, Cen Chen</em><br>
    <div style="background-color: #f9f9f9; border-left: 4px solid #5fbbf3; padding: 10px; color: #808080; font-size: 80%; margin-top: 8px;">
      <strong>TL;DR:</strong> A privacy-preserving inference framework that removes privacy information from user inputs and restores them on the server via activation steering using a protected meta-vector, ensuring data privacy without retraining.
    </div>
  </div>
</div>

<div class="paper-card">
  <div style="width: 100px; margin-right: 20px; flex-shrink: 0; display: flex; flex-direction: column; gap: 10px;">
    <a href="https://arxiv.org/abs/2502.18517" style="display: block;">
      <img src="images/rewardds.png" alt="rewardds" style="width: 100px; height: 100px; object-fit: cover; border-radius: 5px; display: block;">
    </a>
    <img src="images/EMNLP2025.jpg" alt="EMNLP2025" style="width: 100px; height: 100px; object-fit: cover; border-radius: 5px; display: block;">
  </div>

  <div style="flex: 1;">
    <strong>[EMNLP 2025 Main]</strong><br>
    <strong><a href="https://arxiv.org/abs/2502.18517" style="text-decoration: underline; color: #52ADC8;">RewardDS: Privacy-Preserving Fine-Tuning for Large Language Models via Reward Driven Data Synthesis</a></strong><br>
    <em>Jianwei Wang, Chengming Shi, <strong>Junyao Yang</strong>, Haoran Li, Huiping Zhuang, Cen Chen, Ziqian Zeng<sup>#</sup></em><br>
    <div style="background-color: #f9f9f9; border-left: 4px solid #5fbbf3; padding: 10px; color: #808080; font-size: 80%; margin-top: 8px;">
      <strong>TL;DR:</strong> A privacy-preserving fine-tuning framework that improves synthetic data quality by using a client-side reward model to filter and refine generated data, mitigating noise while protecting private information.
    </div>
  </div>
</div>


<span style="color: grey;"><sub>(<sup>\*</sup> co-author, <sup>#</sup> correspondence author)</sub></span>

âœï¸ Education {#education}
======
<p>
    <img src="images/NUS.jpg" alt="NUS" style="float: right; margin-right: 20px;; width: 80px; height: 80px;">
</p>
- **National University of Singapore**, Singapore <br>
  M.S. in Artificial Intelligence <br>
  2025 ~ 2027 (expected) <br>
<p>
    <img src="images/South_China_University_of_Technology_Logo_(Since_2022).svg.png" alt="SCUT" style="float: right; margin-right: 20px;; width: 80px; height: 80px;">
</p>
- **South China University of Technology**, Guangzhou, China  
  B.E. in Computer Science Union Class (top 30 students in undergraduates)  
  2021 ~ 2025
<p>
    <img src="images/SZSY_Logo.png" alt="SZSY" style="float: right; margin-right: 20px;; width: 80px; height: 80px;">
</p>
- **Shenzhen Experimental School**, Shenzhen, China  
  High School Diploma  
  2018 ~ 2021

ğŸ’» Experience {#experience}
======
<p>
    <img src="images/ailab.png" alt="ailab" style="float: right; margin-right: 20px;; width: 80px; height: 80px;">
</p>
- 2025.06 ~ Present, Research Intern, Shanghai AI Lab <br>
  Supervisor: [Dongrui Liu](https://shenqildr.github.io/), Collaborator: [Chen Qian](https://scholar.google.com/citations?user=knR4ZusAAAAJ&hl=en), Shanghai, China. <br>
  Topics: Trustworthy Machine Learning & LLM Reasoning <br>
<p>
    <img src="images/South_China_University_of_Technology_Logo_(Since_2022).svg.png" alt="SCUT" style="float: right; margin-right: 20px;; width: 80px; height: 80px;">
</p>
- 2024.07 ~ Present, Research Intern, South China University of Technology <br>
  Supervisor: Prof. [Ziqian Zeng](https://ziqianzeng.github.io/), Collaborator: [Jianwei Wang](https://scholar.google.com/citations?user=eRFVxQ8AAAAJ&hl=zh-CN), [Haoran Li](https://hlibt.student.ust.hk/), Guangzhou, China. <br>
  Topics: LLM Privacy & Reasoning <br>
<p>
    <img src="images/Tencent.png" alt="Tencent" style="float: right; margin-right: 20px;; width: 80px; height: 80px;">
</p>
- 2024.04 ~ 2024.07, Machine Learning Intern, **[Tencent](https://kf.qq.com/)**, Shenzhen, China. <br>
  Topics: LLM Deployment & Fine-Tuning <br>
  
<p style="clear: both;">
    <img src="images/SZSE.png" alt="szse" style="float: right; margin-right: 20px; width: 80px; height: 80px;">
</p>
- 2024.01 ~ 2024.04, Machine Learning Intern, **[SZSE](https://www.szse.cn/English/index.html)**, Shenzhen, China. <br>
  Topics: LLM Acceleration & Memory Optimizing  <br>

<p style="clear: both;">
    <img src="images/South_China_University_of_Technology_Logo_(Since_2022).svg.png" alt="SCUT" style="float: right; margin-right: 20px; width: 80px; height: 80px;">
</p>
- 2023.06 ~ 2024.08, Research Intern, South China University of Technology <br>
  Supervisor: Prof. [Guanglong Du](https://www2.scut.edu.cn/duguanglong/), Guangzhou, China. <br>
  Topics: Reinforcement Learning & UAV Navigation <br>
  
ğŸ–ï¸ Honor and Awards {#honor}
======
-	[2024.10] Second-Class Scholarship of South China University of Technology
- [2024.11 & 2023.11 & 2022.11] Outstanding Student Leader 
- [2024.11 & 2023.11 & 2022.11] Merit Student 
- [2023.05] Outstanding Student Union Member
- [2022.10] Third-Class Scholarship of South China University of Technology
- [2022.09] Second-Class Award in CUMCM at Guangdong Province 

ğŸ“˜ Patents
======
**An Intelligent Obstacle Avoidance and Destination Landing Unmanned Aerial Vehicles Based on Multi-Layer Neural Networks**<br>
*Guanglong Du, Xiaojian Qiu, **Junyao Yang**, Jiancheng Li, Xueqian Wang, Xiaojun Zhu* (Student First Author)<br>
2023.08  Publication Number: CN117170403A  
